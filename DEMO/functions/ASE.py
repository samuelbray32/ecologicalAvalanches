import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import scipy
import scipy.ndimage
import time


def avFamily(normPath,Tfam,b,gam=1.5):
    """
    #given system scaling and norm shape, returns family of avalanche curves
    normPath = pth to reference average avalanche trajectory (generated by linear repsponse model in this work)
    Tfam = set of avalanche durations to extrapolate
    b = fit value for size of unit duration ovalanche
    gam = scaling exponent (<S> = bT^gam). Theoretical value used as default
    """
    yNorm=np.load(normPath)
    xNorm=np.linspace(0,1,yNorm.size)
    yFunc=scipy.interpolate.interp1d(xNorm,yNorm,kind='quadratic')
    def xT(T):
        return np.linspace(0,T,T)
    def yT(T):
        return b*T**(gam-1)*yFunc(np.linspace(0,1,T))
    t=[]
    S=[]
    for dur in Tfam:
        t.append(xT(dur))
        S.append(yT(dur))
    return t,S

def bFit(T,S,gam=1.5):
    """
    #Gets the log intercept value b needed to extrapolate family of curves
    Fits the value b from (<S> = bT^gam).
    T = avalanche durations in historical data
    S = avalanche sizes in historical data
    gam = exponent. default the theoretical value
    """
    from scipy.optimize import curve_fit
    def func(t,lb):
        return gam*t+lb
    T=np.log10(T)
    S=np.log10(S)
    popt,pcov=curve_fit(func, T, S)
    return 10**popt[0]

def avalancheDist_ASE(data,thresh,t=0):
    """
    #extracts location and size of avalanches
    #use in fitting of b for data
    """
    if t==0:
        t=np.linspace(0,data.size-1,data.size)
    st=[]
    en=[]
    dt=np.zeros(t.size)
    dt[1:]=t[1:]-t[:-1]
    for i in range (data.size):
        if len(st)==len(en):
            if data[i]>=thresh:
                st.append(i)
            continue
        if len(st)>len(en):
            if data[i]<thresh:
                en.append(i)
    if len(st)>len(en):
        en.append(data.size-1)
    st=np.array(st).astype(int)
    en=np.array(en).astype(int)
    #print(st.shape)
    T=t[en]-t[st]
    S=np.zeros(T.size)
    for i in range (st.size):
        S[i]=np.sum((data[st[i]:en[i]]-thresh)*dt[st[i]:en[i]])
    #Pathological case when small dataset
    S=np.abs(S)
    #Safety check for size one avalanches:
    ind=np.where(S>0)
    S=S[ind]
    T=T[ind]
    #Pathological case when small dataset
    if len(T)==0:
        pl=np.where(data>thresh)
        if np.sum(data[pl])>0:
            T=np.array([len(pl)])
            S=np.array([np.sum(data[pl])])
    return T,S

def ASE(data, normPath, Tfam, gam=1.5):
    """
    Avalanche Scaling Extrapolation
    generates a set of scaled average avalanche trajectories based on data
    data = potentially small set of historical data
    normPath = pth to reference average avalanche trajectory (generated by linear repsponse model in this work)
    Tfam = set of avalanche durations to extrapolate
    gam = scaling exponent (<S> = bT^gam). Theoretical value used as default
    """
    #identify avalanche events
    t,s=avalancheDist_ASE(data-np.mean(data),0)
    #check that there is some variation to fit on
    if len(t)<1: 
        print('insufficient data')
        return False
    #fit for unit avalanche size
    else:
        b=bFit(t,s)
    #extrapolate average curve by fit scaling
    t_ASE,fit_ASE=avFamily(normPath, Tfam, b, gam)
    return t_ASE, fit_ASE
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    